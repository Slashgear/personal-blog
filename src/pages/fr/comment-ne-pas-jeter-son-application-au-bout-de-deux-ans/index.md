---
title: "Bonnes pratiques pour la maintenance d'une application web"
description: "Comment ne pas jeter son projet au bout de 2 ans ? Retour d'exp√©rience bas√©s sur les bonnes pratiques appliqu√©es √† la plateforme web d√©velopp√©e chez Bedrock Streaming."
date: 2021-08-05
hero: ./bedrock.jpg
language: fr
translations: ['en', 'how-not-to-trash-your-project']
tags:
  - web
  - javascript
  - bedrock
---

> Comment ne pas jeter son application tous les deux ans ?

_Retour d'exp√©rience bas√©s sur les bonnes pratiques appliqu√©es √† la plateforme web d√©velopp√©e chez [Bedrock Streaming](https://www.bedrockstreaming.com/)_

## Un peu de contexte

√Ä Bedrock Streaming de nombreuses √©quipes d√©veloppent et maintiennent diff√©rentes applications frontend pour nos clients et utilisateurs.
Certaines de ces applications ne sont pas toute jeune.
En effet, si on prend l'exemple de l'application sur laquelle je travaille principalement, il s'agit d'un site web dont les d√©veloppements ont commenc√© en 2014.
J'ai d'ailleurs d√©j√† √©voqu√© celle-ci dans diff√©rents articles de ce blog.

![impression d'√©cran du nombre de commit sur master de notre projet 15668](./commit-count.png)

Vous pourriez vous dire: _"Oh les pauvres maintenir une application vieille de presque 10 ans √ßa doit √™tre un enfer !"_

Rassurez-vous, ce n'est pas le cas !
J'ai par le pass√© travaill√© sur des projets frontend bien moins vieux mais sur lesquelles le d√©veloppement de nouvelles fonctionnalit√©s √©tait bien plus p√©nible.

Aujourd'hui le projet reste √† jour techniquement, on doit √™tre sur la derni√®re version de React alors que celui-ci avait commenc√© sur une version _0.x.x_.
Dans ce monde des technologies web souvent d√©cri√© (ex: les nombreux sur la _Javascript Fatigue_) dont les outils et les pratiques √©voluent constamment, conserver un projet "√† jour" reste un vrai challenge.

![nombre de version de l'application 1445](./releases.png)

De plus, dans le contexte de ce projet sp√©cifique, en presque 10 ans, nous avons connu une centaine de contributeurs diff√©rents.
Certains contributeurs ne sont rest√©s que quelques mois/ann√©es, comment ne pas perdre des infos ?
Comment fait-on pour garder au maximum la connaissance sur "Comment on fait les choses et comment √ßa marche ?".

![liste des 100 contributeurs du projet](./contributors.png)

C'est ce que je vous propose de vous pr√©senter dans cet article.
Avec l'aide de mes coll√®gues, j'ai rassembl√© la liste des bonnes pratiques qui nous permettent encore aujourd'hui de maintenir ce projet en √©tat.
Avec [Florent Dubost](https://twitter.com/fooragnak), on s'est souvent dit qu'il serait int√©ressant de les lister.
Ne serait-ce que pour le partager en interne √† Bedrock.
Quitte √† en faire la liste, autant vous le partager √©galement, en esp√©rant que cela vous soit utile.

## S'imposer des r√®gles et les automatiser

Un projet qui r√©siste c'est tout d'abord un ensemble de connaissances qu'on empile les unes sur les autres.
C'est en quelque sorte la tour de Kapla que vous assembliez petit en essayant d'aller le plus haut possible.
On essaye alors de construire des bases solides d√®s le d√©but sinon on est certain qu'on ira pas tr√®s haut.

D√®s le d√©but d'un projet on est donc amen√© √† prendre de d√©cisions importantes sur "Comment on souhaite faire les choses ?".
On pense par exemple √† "Quel format pour nos fichiers ? Comment on nomme telle ou telle chose ?"
√âcrire une documentation pr√©cise de "Comment on fait les choses" pourrait paraitre une bonne id√©e.

Cependant la documentation c'est cool, mais √ßa a tendance √† p√©rimer tr√®s vite.
Nos d√©cisions √©voluent mais pas la documentation.

> "Les temps changent mais pas les README."
>
> [_Olivier Mansour (deputy CTO √† Bedrock)_](https://twitter.com/omansour)

On trouve qu'automatiser la v√©rification de chacune des r√®gles qu'on s'impose sur notre codebase ou nos process est bien plus p√©renne.
En plus de √ßa, cot√© JS on est vraiment bien √©quip√© avec des outils comme Eslint qui nous permettent d'impl√©menter nos propres r√®gles.

Le r√©flexe qu'on essaie donc d'adopter est donc le suivant:

- "On devrait essayer de faire comme cela √† pr√©sent !"
- "Ok c'est int√©ressant, mais comment peut-on s'assurer qu'on le fasse comme cela automatiquement avec notre CI ?"

Il n'y a rien de mieux que l'int√©gration continue d'un projet pour ne rien louper sur chacune des _Pull Request_ qu'on est amen√© √† proposer.
Les reviews n'en sont que plus simple car vous n'avez plus √† vous soucier de l'ensemble des r√®gles qui sont d√©j√† automatis√©es.
Dans ce mod√®le, la review sert donc plus au partage de connaissance qu'au flicage de typo et autre non respect des conventions du projet.

Dans ce principe, il faut donc essayer de bannir les r√®gles orales.
Le temps des druides est termin√©, si il faut transmettre oralement toutes les bonnes pratiques d'un projet, l'accompagnement de nouveaux d√©veloppeurs dans votre √©quipe n'en sera que plus long.

![la recette de la potion magique de panoramix est perdue car secr√®te](./panoramix.gif)

√âtant donn√© qu'un projet n'est pas quelque chose de fig√©, ces r√®gles vont √©voluer avec le temps.
On pr√©f√®rera alors l'ajout de r√®gles qui poss√®dent un script qui _autofixera_ toute la codebase intelligemment.
De nombreuses r√®gles Eslint le propose, et cela est vraiment un crit√®re de s√©lection tr√®s important dans nos choix de nouvelles conventions.
Un r√®gle tr√®s stricte qui vous obligera √† modifier votre code manuellement avant chaque push est p√©nible √† la longue et √©nervera vos √©quipes.
Alors qu'une r√®gle (m√™me tr√®s stricte) qui peut s'autofixer automatiquement au moment du commit ne sera pas per√ßu comme g√™nante.

**Comment d√©cider d'ajouter de nouvelles r√®gles ?**

Cette question peut paraitre √©pineuse, prenons par exemple le cas des `<tab>` / `<space>` dans les fichiers.
Pour cela, on essaye d'√©viter des d√©bats sempiternel et on se plie √† la tendance et aux r√®gles de la communaut√©.
Par exemple, notre base de configuration Eslint est bas√©e sur celle d'Airbnb qui semble avoir un certain succ√®s dans la communaut√© JS.

### La liste _presque_ exhaustive ü§û

<details>
<summary style='font-weight: bold; font-style: italic'>√âtant donn√© que cet article est d√©j√† suffisamment long, voici la liste des r√®gles qu'on s'impose sur le projet et qui pourraient vous servir d'exemple (clique sur ce texte pour les faires apparaitre)</summary>

![Notre workflow d'int√©gration continue](./ci-workflow.png)

- Le format des fichiers est suivi g√©r√© par editorconfig, prettier et eslint.
  Nous avons opensourc√© [notre propre configuration](https://github.com/M6Web/eslint-tools), si jamais celle-ci peut vous √™tre utile.
- On utilise un [nommage de commit bien sp√©cifique](https://www.conventionalcommits.org/en/v1.0.0/) pour g√©n√©rer nos changelog.
  Pour s'assurer que les devs le respectent, une simple √©tape de notre CI le v√©rifie.
- On ne souhaite pas qu'un dev fasse grossir √©norm√©ment nos bundle en production, c'est pourquoi nous suivont et mesuront leur taille dans la CI.
- La couverture de tests n'est pas un indicateur pour nous, toutes les lignes n'ont pas la m√™me n√©cessit√© pour nous d'√™tre test√©e.
- Nos tests unitaires tournent bien √©videmment sur la CI, ceux-ci doivent passer.
- Nos tests fonctionnels (E2E) tournent sur Chrome Headless, ils doivent √™tre au vert.
- Les logs de nos tests fonctionnels sont r√©cup√©r√©s est pars√©s afin d'√©viter l'introduction d'erreur ou de react warning (Le script de parsing est cependant compliqu√© √† maintenir)
- Les tests fonctionnels fonctionnent dans une sandbox ou tout le r√©seau est proxyfi√©.
  Nous surveillons que nos tests ne d√©pendent pas d'une API non moqu√©e qui pourrait ralentir leur execution.
- On v√©rifie quelques r√®gles sur le CSS avec [Stylelint](https://stylelint.io/) et [bemlinter](https://github.com/M6Web/bemlinter) (on utilise plus BEM aujourd'hui mais il reste encore un peu de style g√©r√© en SCSS qu'on migre petit √† petit)
- Le projet est un monorepo sur lequel nous essayons de maintenir les m√™mes version de d√©pendances pour chaque package.
  Pour cela nous avons d√©velopp√© un outil qui permet de faire cette v√©rification _[monorepo-dependencies-check](https://www.npmjs.com/package/monorepo-dependencies-check)_
- On v√©rifie que le notre fichier `yarn.lock` n'a pas √©t√© modifi√© par inadvertance ou bien qu'il a √©t√© bien mis √† jour par rapport aux modifications du `package.json`.
- Terraform est utilis√© pour la gestion de nos ressources cloud, nous v√©rifions que le format des fichiers est correct.
- Durant les tests e2e nous v√©rifions qu'aucune requ√™te d'image n'a g√©n√©r√© une 404.
- On r√©alise quelques [v√©rifications d'accessibilit√© avec Axe](https://www.deque.com/axe/) durant nos tests e2e.

</details>

## Tester, tester et tester

J'esp√®re qu'en 2021 il n'est plus n√©cessaire d'expliquer pourquoi tester automatiquement son application est indispensable pour la rendre p√©renne.
En JS on est plut√¥t bien √©quip√© pour tester aujourd'hui.
Il reste cependant l'√©ternelle question:

> "Qu'est-ce qu'on veut tester ?"

Globalement si on recherche sur internet cette question, on voit que des besoins diff√©rents font √©merger des pratiques et des outils de testing bien diff√©rents.
Ce serait tr√®s pr√©somptueux de penser qu'il y a une bonne mani√®re de tester automatiquement son application.
C'est pourquoi il est pr√©f√©rable de d√©finir une ou plusieurs strat√©gies de test qui r√©pondent √† nos besoins.

Nos strat√©gies de tests reposent sur deux volont√©s bien distinctes:

- Automatiser la v√©rification des fonctionnalit√©s propos√©es aux utilisateurs de la mani√®re la plus fid√®le √† ce qu'il peut se passer en production
- Nous fournir des solutions efficace pour specifier la mani√®re dont nous impl√©mentons nos solutions techniques pour nous permettre de les faire √©voluer plus facilement.

Pour cela, nous r√©alisons deux "types de tests" que je propose de vous pr√©senter ici.

### Nos tests E2E

On les appelle "tests fonctionels", ce sont des tests End-to-end (E2E) sur une stack technique tr√®s efficace compos√©e de [CucumberJS](https://cucumber.io/docs/installation/javascript/), [WebdriverIO](https://webdriver.io/) avec [ChromeHeadless](https://developers.google.com/web/updates/2017/04/headless-chrome)
Il s'agit d'une stack technique mise en place au d√©but du projet (√† l'√©poque avec [PhantomJS](https://phantomjs.org/) pour les plus anciens d'entre-vous)

Cette stack nous permet d'automatiser le pilotage de tests qui contr√¥lent un navigateur.
Ce navigateur va r√©aliser des actions qui se rapprochent le plus de celles que nos vrais utilisateurs peuvent r√©aliser tout en v√©rifiant comment le site r√©agit.

Il y a quelques ann√©es, cette stack technique √©tait plut√¥t compliqu√©e √† mettre en place, mais aujourd'hui il est plut√¥t simple de le faire.
[Le site qui h√©berge cet article de blog](https://github.com/Slashgear/slashgear.github.io) en est lui-m√™me la preuve.
Il ne m'a fallu qu'une dizaine de minutes pour mettre en place cette stack avec [le WebdriverIo CLI](https://webdriver.io/docs/gettingstarted) pour v√©rifier que mon blog fonctionne comme pr√©vu.

Voici donc un exemple de fichier de test E2E pour vous donner une id√©e:

```gherkin
Feature: Playground

  Background: Playground context
    Given I use "playground" test context

  Scenario: Check if playground is reachable
    When As user "cytron@m6.fr" I visit the "playground" page
    And I click on "playground trigger"
    Then I should see a "visible playground"
    And I should see 4 "playground tab" in "playground"

    When I sleep 1 seconds to wait for full playground load
    And I click on "playground trigger"
    Then I should not see a "visible playground"

    # ...
```

Et √ßa donne √ßa en local !

<video controls style="width: 100%">
  <source src="https://user-images.githubusercontent.com/6263857/129066094-604693a8-8e05-4908-beff-94f2e936f07d.mp4" type="video/mp4">
</video>

Voil√† un petit sch√©ma qui explique un peu comment cette stack fonctionne:

![sch√©ma qui explique le fonctionnement de notre stack](./e2e-archi.png)

Aujourd'hui, l'application web de Bedrock poss√®de plus de 800 sc√©narios de tests E2E qui tournent sur chacune de nos _Pull Request_ et sur la branche `master`.
Ils nous assurent que nous n'introduisons pas de r√©gression fonctionnelle et c'est juste g√©nial !

üëç Les points positifs

- WebdriverIO nous permet √©galement de lancer de mani√®re journali√®re ces m√™mes tests sur des vrais device en passant par le service [Browserstack](https://www.browserstack.com/).
  On a donc tous les jours un job qui s'assure que notre site fonctionne correctement sur un Chrome derni√®re version sur Windows 10 et Safari Macos.
- Ces tests nous permettent de facilement documenter les fonctionnalit√©s de l'application.
- Ils nous permettent de reproduire des cas qui sont loin d'√™tre nominaux.
  Dans une logique TDD, ils permettent d'avancer sur le d√©veloppement sans avoir √† cliquer pendant des heures.
- Ces tests nous ont permis de ne pas casser l'ancienne version du site qui est toujours en production pour quelques clients alors que nos efforts se concentrent sur la nouvelle.
- Ils nous apportent une vraie confiance
- Gr√¢ce notre libraire [_superagent-mock_](https://www.npmjs.com/package/superagent-mock), nous pouvons _fixturer_ (bouchonner, mocker) toutes les API dont on d√©pend et ainsi m√™me v√©rifier les cas d'erreurs.
  De plus, mocker la couche XHR du navigateur permet une am√©lioration siginificative du temps d'ex√©cution des tests. üöÄ
- Ils nous donne acc√®s √† des usages √©tendus comme :
  - v√©rification de r√®gles d'accessibilit√©
  - check les logs de la console navigateur (pour ne pas introduire d'erreur ou de React Warning par exemple)
  - surveiller tous les appels r√©seaux du site gr√¢ce √† un proxy
  - et j'en passe...

üëé Les complications

- Maintenir cette stack est compliqu√© et co√ªteux.
  √âtant donn√© que peu de ressources sont publi√©es sur ce domaine, on se retrouve parfois √† devoir creuser pendant plusieurs jours pour les r√©parer üòÖ.
  Il nous arrive de nous sentir parfois bien seul √† avoir ces soucis.
- Il est tr√®s facile de coder un test E2E dit _flaky_ (ie: un test qui peut √©chouer al√©atoirement), ils font perdre du temps.
  Ils nous font croire que quelque chose est cass√©.
  Ils nous prennent parfois du temps √† les stabiliser.
  Il reste cependant **bien meilleur de ne pas conserver un test qui ne vous donnera pas un r√©sultat stable.**
- Faire tourner tous les tests prend un temps important sur notre int√©gration continue.
  Il faut r√©guli√®rement travailler sur leur optimisation pour que le feedback qu'ils vous apportent soit le plus rapide possible.
  Ces temps importants coutent √©galement de l'argent, il faut en effet bien faire tourner ces tests sur des machines.
  Pour information, l'infrastructure du site web (√† lui seul, juste l'h√©bergement de nos servers Node + fichiers statiques + CDN) coutent bien moins cher que notre int√©gration continue.
  Cela fait bien √©videmment sourire nos Ops ! üòä
- Les nouvelles recrues de nos √©quipes ont souvent jamais r√©alis√©s ce genre de tests, il y a donc une phase ~~de gal√®re~~ d'apprentissage..
- Certaines fonctionnalit√©s sont parfois trop compliqu√©es √† tester avec notre stack E2E (par exemple, les parcours de paiement qui d√©pendent de tiers).
  Il nous arrive alors de nous rabattre sur d'autres techniques avec Jest notamment en ayant un scope moins unitaire.

### Nos tests "unitaires"

- expliquer notre strat√©gie de test
- montrer le kikimeter de nos tests Jest
- la performance, l'automock
- nos soucis avec React-testing-lib
- la n√©cessit√© de faire des tests d'int√©gration dans certain cas

### Nos principes

Nous essayons de toujours respecter les r√®gles suivantes lors qu'on se pose la question "Dois-je ajouter des tests ?".

1. Si notre _Pull Request_ introduit des nouvelles fonctionnalit√©s utilisateurs, il faut int√©grer des scenari de test E2E.
   Des tests unitaires avec Jest peuvent les compl√©ter / remplacer en fonction.
2. Si notre _Pull Request_ a pour but de corriger un bug, cela signifie qu'il nous manque un cas de test.
   On doit donc essayer de rajouter un test E2E ou √† d√©faut un test unitaire.

_C'est en √©crivant ces lignes que je me dis que ces principes pourraient tr√®s bien faire l'objet d'une automatisation._ ü§£

## Le projet reste, les fonctionnalit√©s non

- expliquer qu'il est pr√©f√©rable de mettre en place du featureflippping plutot que de devoir enlever/remttre le code ou jongler avec les branches
- Cela permet de l'A/B testing
- Cela permet de d√©velopper petit √† petit des nouvelles fonctionnalit√©s sans les ativer en prod
- Couper une feature qui plante en prod
- Dans le cas d'un multi clients, proposer les feature en mode buffet
- quand une feature marche plus, on la coupe puis on nettoie
- parenth√®se sur le futurflipping

## Monitorer, Mesurer, Alerter

- le monitoring et l'alerting est tr√®s important pout suivre les fonctionnalit√©, s'assurer qu'elles marchent en prod et d√©cider si on peut les enlever.
- aucune feature ne marche tant qu'elle n'est pas suivie mesurable
- quand on a des mesures solides, on peut mettre en place de l'alerting
- les mesures peuvent nous permettre de prendre de d√©cisions
- les alertes doivent √™tre actionnable pour ne pas faire du bruit inutile
- de l'importance de la data dans les d√©cisions

## Limiter, surveiller et mettre √† jour ses d√©pendances

- sans m√™me toucher √† votre projet, il p√©rime de lui-m√™me avec ses d√©pendances
- il faut mieux parfois √©viter de dependre de lib non maintenues
- les libs de composants graphique peuvent vous aider au d√©but, mais elle cr√©eent des interd√©pendances
- yarn audit task
- yarn outdated et dependabot

## Accepter sa dette technique

Un projet accumulera toujours de la dette technique.
C'est un fait.
Que ce soit de la dette volontaire ou involontaire, un projet qui r√©siste aux ann√©es va forc√©ment accumuler de la dette.
D'autant plus, si pendant toutes ces ann√©es vous continuez d'ajouter des fonctionnalit√©s.

Depuis 2014, nos bonnes pratiques, nos fa√ßons de faire ont bien √©volu√©.
Parfois nous avons d√©cid√© ces changements mais parfois nous les avons subi (un exemple, l'arriv√©e des composants fonctionnels avec React et l'api des Hooks).

**Notre projet n'est pas _"state of art"_ et on l'assume.**

<iframe src="https://giphy.com/embed/JGunlb6LbQlz2" width="480" height="270" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

Nous essayons de prioriser nos sujets de _refactoring_ sur les parties de l'application sur lequel on a le plus de souci, le plus de peine.
On consid√®re qu'une partie de l'application qui nous pla√Æt pas mais sur laquelle on n'a pas besoin de travailler (apporter des √©volution) ne m√©rite pas qu'on la refactor.

Je pourrais vous citer de nombreuses fonctionnalit√©s de notre application qui n'ont pas √©volu√© fonctionnellement depuis plusieurs ann√©es.
Mais comme nous avons couvert ces fonctionnalit√©s de tests E2E depuis le d√©but, nous n'avons pas vraiment eu √† y retoucher.

Avec notre architecture de _feature flipping_, la prochaine √©volution d'un bon de code est parfois sa d√©sactivation.
Alors pourquoi passez son temps √† r√©-√©crire toute l'application ?

- Le code devient dans tous les cas du legacy.
- Tant que les fonctionnalit√©s sont test√©es, rien ne vous oblige √† tout refactorer en permanence pour que toute votre codebase soit staet of art.
- On se focus sur nos pain point

## Pour r√©sumer

Les bonnes pratiques pr√©sent√©es ici restent bien √©videmment subjectives et ne s'appliqueront pas parfaitement/directement dans vos contextes.
Je suis cependant convaincu qu'elles peuvent probablement vous aider √† identifier ce qui peut faire passer votre projet de fun √† p√©rim√©.
√Ä Bedrock nous avons mis en place d'autres pratiques que je n'ai pas list√©es ici mais ce sera l'occasion de faire un nouvel article un jour.
