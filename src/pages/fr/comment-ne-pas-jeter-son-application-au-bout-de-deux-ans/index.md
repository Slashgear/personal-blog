---
title: "Bonnes pratiques pour la maintenance d'une application web"
description: "Comment ne pas jeter son projet au bout de 2 ans ? Retour d'exp√©rience bas√©s sur les bonnes pratiques appliqu√©es √† la plateforme web d√©velopp√©e chez Bedrock Streaming."
date: 2021-08-05
hero: ./bedrock.jpg
language: fr
translations: ['en', 'how-not-to-trash-your-project']
tags:
  - web
  - javascript
  - bedrock
---

> Comment ne pas jeter son application tous les deux ans ?

_Retour d'exp√©rience bas√©s sur les bonnes pratiques appliqu√©es √† la plateforme web d√©velopp√©e chez [Bedrock Streaming](https://www.bedrockstreaming.com/)_

## Un peu de contexte

√Ä Bedrock Streaming de nombreuses √©quipes d√©veloppent et maintiennent diff√©rentes applications frontend pour nos clients et utilisateurs.
Certaines de ces applications ne sont pas toute jeune.
En effet, si on prend l'exemple de l'application sur laquelle je travaille principalement, il s'agit d'un site web dont les d√©veloppements ont commenc√© en 2014.
J'ai d'ailleurs d√©j√† √©voqu√© celle-ci dans diff√©rents articles de ce blog.

![impression d'√©cran du nombre de commit sur master de notre projet 15668](./commit-count.png)

Vous pourriez vous dire: _"Oh les pauvres maintenir une application vieille de presque 10 ans √ßa doit √™tre un enfer !"_

Rassurez-vous, ce n'est pas le cas !
J'ai par le pass√© travaill√© sur des projets frontend bien moins vieux mais sur lesquelles le d√©veloppement de nouvelles fonctionnalit√©s √©tait bien plus p√©nible.

Aujourd'hui le projet reste √† jour techniquement, on doit √™tre sur la derni√®re version de React alors que celui-ci avait commenc√© sur une version _0.x.x_.
Dans ce monde des technologies web souvent d√©cri√© (ex: les nombreux sur la _Javascript Fatigue_) dont les outils et les pratiques √©voluent constamment, conserver un projet "√† jour" reste un vrai challenge.

![nombre de version de l'application 1445](./releases.png)

De plus, dans le contexte de ce projet sp√©cifique, en presque 10 ans, nous avons connu une centaine de contributeurs diff√©rents.
Certains contributeurs ne sont rest√©s que quelques mois/ann√©es, comment ne pas perdre des infos ?
Comment fait-on pour garder au maximum la connaissance sur "Comment on fait les choses et comment √ßa marche ?".

![liste des 100 contributeurs du projet](./contributors.png)

C'est ce que je vous propose de vous pr√©senter dans cet article.
Avec l'aide de mes coll√®gues, j'ai rassembl√© la liste des bonnes pratiques qui nous permettent encore aujourd'hui de maintenir ce projet en √©tat.
Avec [Florent Dubost](https://twitter.com/fooragnak), on s'est souvent dit qu'il serait int√©ressant de les lister.
Ne serait-ce que pour le partager en interne √† Bedrock.
Quitte √† en faire la liste, autant vous le partager √©galement, en esp√©rant que cela vous soit utile.

## S'imposer des r√®gles et les automatiser

Un projet qui r√©siste c'est tout d'abord un ensemble de connaissances qu'on empile les unes sur les autres.
C'est en quelque sorte la tour de Kapla que vous assembliez petit en essayant d'aller le plus haut possible.
On essaye alors de construire des bases solides d√®s le d√©but sinon on est certain qu'on ira pas tr√®s haut.

D√®s le d√©but d'un projet on est donc amen√© √† prendre de d√©cisions importantes sur "Comment on souhaite faire les choses ?".
On pense par exemple √† "Quel format pour nos fichiers ? Comment on nomme telle ou telle chose ?"
√âcrire une documentation pr√©cise de "Comment on fait les choses" pourrait paraitre une bonne id√©e.

Cependant la documentation c'est cool, mais √ßa a tendance √† p√©rimer tr√®s vite.
Nos d√©cisions √©voluent mais pas la documentation.

> "Les temps changent mais pas les README."
>
> [_Olivier Mansour (deputy CTO √† Bedrock)_](https://twitter.com/omansour)

On trouve qu'automatiser la v√©rification de chacune des r√®gles qu'on s'impose sur notre codebase ou nos process est bien plus p√©renne.
En plus de √ßa, cot√© JS on est vraiment bien √©quip√© avec des outils comme Eslint qui nous permettent d'impl√©menter nos propres r√®gles.

Le r√©flexe qu'on essaie donc d'adopter est donc le suivant:

- "On devrait essayer de faire comme cela √† pr√©sent !"
- "Ok c'est int√©ressant, mais comment peut-on s'assurer qu'on le fasse comme cela automatiquement avec notre CI ?"

Il n'y a rien de mieux que l'int√©gration continue d'un projet pour ne rien louper sur chacune des _Pull Request_ qu'on est amen√© √† proposer.
Les reviews n'en sont que plus simple car vous n'avez plus √† vous soucier de l'ensemble des r√®gles qui sont d√©j√† automatis√©es.
Dans ce mod√®le, la review sert donc plus au partage de connaissance qu'au flicage de typo et autre non respect des conventions du projet.

Dans ce principe, il faut donc essayer de bannir les r√®gles orales.
Le temps des druides est termin√©, si il faut transmettre oralement toutes les bonnes pratiques d'un projet, l'accompagnement de nouveaux d√©veloppeurs dans votre √©quipe n'en sera que plus long.

![la recette de la potion magique de panoramix est perdue car secr√®te](./panoramix.gif)

√âtant donn√© qu'un projet n'est pas quelque chose de fig√©, ces r√®gles vont √©voluer avec le temps.
On pr√©f√®rera alors l'ajout de r√®gles qui poss√®dent un script qui _autofixera_ toute la codebase intelligemment.
De nombreuses r√®gles Eslint le propose, et cela est vraiment un crit√®re de s√©lection tr√®s important dans nos choix de nouvelles conventions.
Un r√®gle tr√®s stricte qui vous obligera √† modifier votre code manuellement avant chaque push est p√©nible √† la longue et √©nervera vos √©quipes.
Alors qu'une r√®gle (m√™me tr√®s stricte) qui peut s'autofixer automatiquement au moment du commit ne sera pas per√ßu comme g√™nante.

**Comment d√©cider d'ajouter de nouvelles r√®gles ?**

Cette question peut paraitre √©pineuse, prenons par exemple le cas des `<tab>` / `<space>` dans les fichiers.
Pour cela, on essaye d'√©viter des d√©bats sempiternel et on se plie √† la tendance et aux r√®gles de la communaut√©.
Par exemple, notre base de configuration Eslint est bas√©e sur celle d'Airbnb qui semble avoir un certain succ√®s dans la communaut√© JS.

### La liste _presque_ exhaustive ü§û

<details>
<summary style='font-weight: bold; font-style: italic'>√âtant donn√© que cet article est d√©j√† suffisamment long, voici la liste des r√®gles qu'on s'impose sur le projet et qui pourraient vous servir d'exemple (clique sur ce texte pour les faires apparaitre)</summary>

![Notre workflow d'int√©gration continue](./ci-workflow.png)

- Le format des fichiers est suivi g√©r√© par editorconfig, prettier et eslint.
  Nous avons opensourc√© [notre propre configuration](https://github.com/M6Web/eslint-tools), si jamais celle-ci peut vous √™tre utile.
- On utilise un [nommage de commit bien sp√©cifique](https://www.conventionalcommits.org/en/v1.0.0/) pour g√©n√©rer nos changelog.
  Pour s'assurer que les devs le respectent, une simple √©tape de notre CI le v√©rifie.
- On ne souhaite pas qu'un dev fasse grossir √©norm√©ment nos bundle en production, c'est pourquoi nous suivont et mesuront leur taille dans la CI.
- La couverture de tests n'est pas un indicateur pour nous, toutes les lignes n'ont pas la m√™me n√©cessit√© pour nous d'√™tre test√©e.
- Nos tests unitaires tournent bien √©videmment sur la CI, ceux-ci doivent passer.
- Nos tests fonctionnels (E2E) tournent sur Chrome Headless, ils doivent √™tre au vert.
- Les logs de nos tests fonctionnels sont r√©cup√©r√©s est pars√©s afin d'√©viter l'introduction d'erreur ou de react warning (Le script de parsing est cependant compliqu√© √† maintenir)
- Les tests fonctionnels fonctionnent dans une sandbox ou tout le r√©seau est proxyfi√©.
  Nous surveillons que nos tests ne d√©pendent pas d'une API non moqu√©e qui pourrait ralentir leur execution.
- On v√©rifie quelques r√®gles sur le CSS avec [Stylelint](https://stylelint.io/) et [bemlinter](https://github.com/M6Web/bemlinter) (on utilise plus BEM aujourd'hui mais il reste encore un peu de style g√©r√© en SCSS qu'on migre petit √† petit)
- Le projet est un monorepo sur lequel nous essayons de maintenir les m√™mes version de d√©pendances pour chaque package.
  Pour cela nous avons d√©velopp√© un outil qui permet de faire cette v√©rification _[monorepo-dependencies-check](https://www.npmjs.com/package/monorepo-dependencies-check)_
- On v√©rifie que le notre fichier `yarn.lock` n'a pas √©t√© modifi√© par inadvertance ou bien qu'il a √©t√© bien mis √† jour par rapport aux modifications du `package.json`.
- Terraform est utilis√© pour la gestion de nos ressources cloud, nous v√©rifions que le format des fichiers est correct.
- Durant les tests e2e nous v√©rifions qu'aucune requ√™te d'image n'a g√©n√©r√© une 404.
- On r√©alise quelques [v√©rifications d'accessibilit√© avec Axe](https://www.deque.com/axe/) durant nos tests e2e.

</details>

## Tester, tester et tester

J'esp√®re qu'en 2021 il n'est plus n√©cessaire d'expliquer pourquoi tester automatiquement son application est indispensable pour la rendre p√©renne.
En JS on est plut√¥t bien √©quip√© pour tester aujourd'hui.
Il reste cependant l'√©ternelle question:

> "Qu'est-ce qu'on veut tester ?"

Globalement si on recherche sur internet cette question, on voit que des besoins diff√©rents font √©merger des pratiques et des outils de testing bien diff√©rents.
Ce serait tr√®s pr√©somptueux de penser qu'il y a une bonne mani√®re de tester automatiquement son application.
C'est pourquoi il est pr√©f√©rable de d√©finir une ou plusieurs strat√©gies de test qui r√©pondent √† nos besoins.

Nos strat√©gies de tests reposent sur deux volont√©s bien distinctes:

- Automatiser la v√©rification des fonctionnalit√©s propos√©es aux utilisateurs de la mani√®re la plus fid√®le √† ce qu'il peut se passer en production
- Nous fournir des solutions efficace pour specifier la mani√®re dont nous impl√©mentons nos solutions techniques pour nous permettre de les faire √©voluer plus facilement.

Pour cela, nous r√©alisons deux "types de tests" que je propose de vous pr√©senter ici.

### Nos tests E2E

On les appelle "tests fonctionels", ce sont des tests End-to-end (E2E) sur une stack technique tr√®s efficace compos√©e de [CucumberJS](https://cucumber.io/docs/installation/javascript/), [WebdriverIO](https://webdriver.io/) avec [ChromeHeadless](https://developers.google.com/web/updates/2017/04/headless-chrome)
Il s'agit d'une stack technique mise en place au d√©but du projet (√† l'√©poque avec [PhantomJS](https://phantomjs.org/) pour les plus anciens d'entre-vous)

Cette stack nous permet d'automatiser le pilotage de tests qui contr√¥lent un navigateur.
Ce navigateur va r√©aliser des actions qui se rapprochent le plus de celles que nos vrais utilisateurs peuvent r√©aliser tout en v√©rifiant comment le site r√©agit.

Il y a quelques ann√©es, cette stack technique √©tait plut√¥t compliqu√©e √† mettre en place, mais aujourd'hui il est plut√¥t simple de le faire.
[Le site qui h√©berge cet article de blog](https://github.com/Slashgear/slashgear.github.io) en est lui-m√™me la preuve.
Il ne m'a fallu qu'une dizaine de minutes pour mettre en place cette stack avec [le WebdriverIo CLI](https://webdriver.io/docs/gettingstarted) pour v√©rifier que mon blog fonctionne comme pr√©vu.

Voici donc un exemple de fichier de test E2E pour vous donner une id√©e:

```gherkin
Feature: Playground

  Background: Playground context
    Given I use "playground" test context

  Scenario: Check if playground is reachable
    When As user "cytron@m6.fr" I visit the "playground" page
    And I click on "playground trigger"
    Then I should see a "visible playground"
    And I should see 4 "playground tab" in "playground"

    When I sleep 1 seconds to wait for full playground load
    And I click on "playground trigger"
    Then I should not see a "visible playground"

    # ...
```

Et √ßa donne √ßa en local !

![Exemple d'ex√©cution de test fonctionnel](./e2e-example.gif)

Voil√† un petit sch√©ma qui explique un peu comment cette stack fonctionne:

![sch√©ma qui explique le fonctionnement de notre stack](./e2e-archi.png)

Aujourd'hui, l'application web de Bedrock poss√®de plus de 800 sc√©narios de tests E2E qui tournent sur chacune de nos _Pull Request_ et sur la branche `master`.
Ils nous assurent que nous n'introduisons pas de r√©gression fonctionnelle et c'est juste g√©nial !

üëç Les points positifs

- WebdriverIO nous permet √©galement de lancer de mani√®re journali√®re ces m√™mes tests sur des vrais device en passant par le service [Browserstack](https://www.browserstack.com/).
  On a donc tous les jours un job qui s'assure que notre site fonctionne correctement sur un Chrome derni√®re version sur Windows 10 et Safari Macos.
- Ces tests nous permettent de facilement documenter les fonctionnalit√©s de l'application.
- Ils nous permettent de reproduire des cas qui sont loin d'√™tre nominaux.
  Dans une logique TDD, ils permettent d'avancer sur le d√©veloppement sans avoir √† cliquer pendant des heures.
- Ces tests nous ont permis de ne pas casser l'ancienne version du site qui est toujours en production pour quelques clients alors que nos efforts se concentrent sur la nouvelle.
- Ils nous apportent une vraie confiance
- Gr√¢ce notre libraire [_superagent-mock_](https://www.npmjs.com/package/superagent-mock), nous pouvons _fixturer_ (bouchonner, mocker) toutes les API dont on d√©pend et ainsi m√™me v√©rifier les cas d'erreurs.
  De plus, mocker la couche XHR du navigateur permet une am√©lioration siginificative du temps d'ex√©cution des tests. üöÄ
- Ils nous donne acc√®s √† des usages √©tendus comme :
  - v√©rification de r√®gles d'accessibilit√©
  - check les logs de la console navigateur (pour ne pas introduire d'erreur ou de React Warning par exemple)
  - surveiller tous les appels r√©seaux du site gr√¢ce √† un proxy
  - et j'en passe...

üëé Les complications

- Maintenir cette stack est compliqu√© et co√ªteux.
  √âtant donn√© que peu de ressources sont publi√©es sur ce domaine, on se retrouve parfois √† devoir creuser pendant plusieurs jours pour les r√©parer üòÖ.
  Il nous arrive de nous sentir parfois bien seul √† avoir ces soucis.
- Il est tr√®s facile de coder un test E2E dit _flaky_ (ie: un test qui peut √©chouer al√©atoirement), ils font perdre du temps.
  Ils nous font croire que quelque chose est cass√©.
  Ils nous prennent parfois du temps √† les stabiliser.
  Il reste cependant **bien meilleur de ne pas conserver un test qui ne vous donnera pas un r√©sultat stable.**
- Faire tourner tous les tests prend un temps important sur notre int√©gration continue.
  Il faut r√©guli√®rement travailler sur leur optimisation pour que le feedback qu'ils vous apportent soit le plus rapide possible.
  Ces temps importants coutent √©galement de l'argent, il faut en effet bien faire tourner ces tests sur des machines.
  Pour information, l'infrastructure du site web (√† lui seul, juste l'h√©bergement de nos servers Node + fichiers statiques + CDN) coutent bien moins cher que notre int√©gration continue.
  Cela fait bien √©videmment sourire nos Ops ! üòä
- Les nouvelles recrues de nos √©quipes ont souvent jamais r√©alis√©s ce genre de tests, il y a donc une phase ~~de gal√®re~~ d'apprentissage..
- Certaines fonctionnalit√©s sont parfois trop compliqu√©es √† tester avec notre stack E2E (par exemple, les parcours de paiement qui d√©pendent de tiers).
  Il nous arrive alors de nous rabattre sur d'autres techniques avec Jest notamment en ayant un scope moins unitaire.

### Nos tests "unitaires"

Pour compl√©ter nos tests fonctionnels nous avons √©galement une stack de tests √©cris avec [Jest].
On qualifie ces tests d'unitaires car nous avons comme principe d'essayer de toujours tester nos modules JS en ind√©pendance des autres.

_Ne d√©battons pas ici sur "Est-ce que ce sont des vrais tests unitaires ?", suffisamment d'articles sur internet traitent de ce sempiternel d√©bat._

On utilise ces tests pour diff√©rentes raisons qui couvrent des besoins que nos tests fonctionnels ne couvrent pas:

- nous aider √† d√©velopper nos modules JS avec des pratiques TDD.
- documenter et d√©crire comment fonctionne un module JS.
- tester des cas limites qui sont tr√®s/trop compliqu√©s √† tester avec nos tests E2E.
- faciliter le refactoring de notre application en nous montrant les impactes techniques de nos modifications.

Avec ces tests, on se met au niveau d'une fonction utilitaire, d'une action Redux, d'un reducer,d'un composant React et on s'assure que les comportements qu'on a souhait√© impl√©menter locallement font ce qu'il est souhaiter.
On se base essentiellement sur [la fonctionnalit√© d'`automock` de Jest](https://slashgear.github.io/discover-jest-hidden-feature-automock/) qui nous propose d'isoler nos modules JS lorsqu'on teste.

![repr√©sentation visuelle de l'automock](./mocked-modules.jpg)

L'image pr√©c√©dente repr√©sente la m√©taphore qui nous permet d'expliquer notre strat√©gie de tests unitaires aux nouveaux arrivant.

> "Il faut s'imaginer que l'application est un mur compos√© de briques unitaires (nos modules), nos testes unitraires doivent tester une √† une les briques en ind√©pendance totale des autres.
> Nos tests fonctionels sont la pour tester le ciment entre les briques."

**Pour r√©sumer, on pourrait dire que nos tests E2E testent _ce que notre application doit faire_, et nos tests unitaire s'assurent eux de v√©rifier _comment √ßa marche._**

Aujourd'hui ce sont plus de 6000 test unitaires qui couvrent notre application et nous permettent de limiter les r√©gressions.

```js
// EXEMPLE DE TEST UNITAIRE DE L'APPLICATION
```

üëç

- [Jest] est vraiment une librairie g√©niale, rapide, compl√®te, bien document√©e.
- Les tests unitaires nous aident beaucoup √† comprendre plusieurs ann√©es apr√®s comment tout cela fonctionne.
- On arrive toujours √† tester unitairement notre code, et cela compl√®te bien nos tests E2E.
- L'`automock` est vraiment pratique pour d√©coupage de tests par modules.

üëé

- Parfois, nous nous sommes trouv√©s limit√©s par notre stack de tests fonctionnels et nous ne pouvions pas uniquement nous baser sur les tests unitaires.
  Il nous manquait quelque chose pour pouvoir s'assurer que le _ciment entre les briques_ fonctionnait comme on le souhaitait.
  Pour cela, nous avons mis en place une deuxi√®me stack de tests [Jest] nomm√© "test d'int√©gration" ou l'`automock` est d√©sactiv√©.
- L'abus de [_Snapshot_](https://jestjs.io/docs/snapshot-testing) est dangereux pour la sant√©.
  L'usage du _"Snapshot testing"_ peut faire gagner du temps sur l'impl√©mentation de vos tests mais peuvent en r√©duire la qualit√©.
  Avec un object de 50 lignes en _Snapshot_ n'est pas forc√©ment lisible √† la review
- Avec la d√©pr√©citation d'[EnzymeJS], nous sommes contraints de migrer sur [React Testing Library].
  Il est bien √©videmment possible de tester unitairement des composants avec cette nouvelle librairie.
  Malheureusement, ce n'est pas vraiment l'esprit et la fa√ßon de faire.
  [React Testing Library] nous pousse [√† ne pas jouer avec le _shallow rendering_](https://kentcdodds.com/blog/why-i-never-use-shallow-rendering).

### Nos principes

Nous essayons de toujours respecter les r√®gles suivantes lors qu'on se pose la question "Dois-je ajouter des tests ?".

1. Si notre _Pull Request_ introduit des nouvelles fonctionnalit√©s utilisateurs, il faut int√©grer des scenari de test E2E.
   Des tests unitaires avec Jest peuvent les compl√©ter / remplacer en fonction.
2. Si notre _Pull Request_ a pour but de corriger un bug, cela signifie qu'il nous manque un cas de test.
   On doit donc essayer de rajouter un test E2E ou √† d√©faut un test unitaire.

_C'est en √©crivant ces lignes que je me dis que ces principes pourraient tr√®s bien faire l'objet d'une automatisation._ ü§£

## Le projet reste, les fonctionnalit√©s non

> "La seconde √©volution d'une fonctionnalit√© est tr√®s souvent sa suppression."

Par principe, nous souhaitons faire en sorte que chaque nouvelle fonctionnalit√©e de l'application ne base pas son activation sur le simple fait d'√™tre dans la codebase.
Classiquement, le cycle de vie d'une "feature" dans un projet peut √™tre le suivant (dans un [Github Flow](https://guides.github.com/introduction/flow/)):

- une personne impl√©mente sur une branche
- la fonctionnalit√© est _merg√©e_ sur master
- elle est d√©ploy√©e en production
- vie sa vie de fonctionnalit√© (avec parfois des bugs et des correctifs)
- la fonctionnalit√© n'est plus n√©cessaire
- une personne d√©tricote le code et l'enl√®ve
- nouveau d√©ploiement

Pour simplifier certaines √©tapes, nous avons mis en place du _feature flipping_ sur le projet.

**Comment √ßa marche ?**

Dans notre config nous avons une map cl√©/valeur qui liste toutes les fonctionnalit√©s de l'application associ√©e √† leur status d'activation.

```js
const featureFlipping = {
  myAwesomeFeature: false,
  anotherOne: true,
}
```

Dans notre code, nous avons donc impl√©menter des traitements conditionnels qui disent "Si cette feature est activ√©e alors...".
Cela peut changer le rendu d'un composant, changer l'impl√©mentation d'une action Redux ou bien d√©sactiv√© un route de notre React-router.

**Mais √† quoi √ßa nous sert ?**

- On peut d√©velopper des nouvelles √©volutions progressivement en les cachant derri√®re une cl√© de configuration.
  On livre des fonctionnalit√©s en production sans les activer.
- En evironnement de test, on peut surcharger cette config pour tester des features qui ne sont pas encore activ√©es en production.
- Dans le cas d'un site en marque blanche, on peut proposer ces fonctionnalit√©s √† nos clients comme des options possibles.
- Avant de supprimer le code d'une feature, on la d√©sactive puis on fait le m√©nage sans risque.
- Gr√¢ce √† un outil maison nomm√© l'_Applaunch_, cette config de feature flipping est surchargeable dans une interface graphique √† chaud sans d√©ploiement de l'application.
  Cela nous permet d'activer des fonctionnalit√©s sans faire de mise en production du code.
  En cas d'incident, on peut d√©sactiver des fonctionnalit√©s qui sont d√©grad√©es.

Pour vous donner un exemple plus concr√®t, entre 2018 et 2020 nous avons compl√®tement refondu l'interface de l'application.
C'est √©volution graphique n'√©tait qu'une cl√© de featureFlipping.
La refonte graphique n'a donc pas √©t√© la remise √† z√©ro du projet, on continue encore aujourd'hui de vivre avec les deux versions (tant que la bascule de tous nos clients n'est pas termin√©s).

![screenshot comparatif v4 / v5 sur 6play]()

### L'A/B testing

Gr√¢ce au super travail de nos √©quipes backend et data, nous avons pu m√™me √©tendre l'usage du _feature flipping_ en rendant cette configuration modifiable pour des sous groupes de nos utilsateurs.
Cela nous permet de d√©ployer nos nouvelles fonctionnalit√©s sur une portion plus r√©duite de nos utilisateurs afin de comparer nos [KPI].

Prise de d√©cision, am√©lioration des performances techniques ou produit, exp√©rimentations, les possibilit√©s sont nombreuses et nous les exploitons de plus en plus.

### Le _futur flipping_

> Sur une id√©e originale de [Florent Lepretre](https://twitter.com/SuperFlaw).

Nous avions r√©guli√®rement le besoin d'activer des feature √† des heures ~~tr√®s~~ trop matinales dans le futur.
Pour cela nous devions √™tre connect√© √† une heure pr√©cise sur notre poste pour modifier la configuration √† chaud.

Afin d'√©viter d'oublier de le faire, ou de le faire en retard, nous avons fait en sorte qu'une cl√© de configuration puisse √™tre activ√©e √† partir d'une certaines date.
Pour cela, nous avons fait √©voluer notre _selector redux_ qui indiquait si une feature √©tait activ√©e pour qu'il puisse g√©rer des format de date et les comparer √† l'heure courante.

```js
// Ajouter un exemple
```

> De nombreux caf√©s ‚òïÔ∏è √† 9h ont √©t√© sauv√©s gr√¢ce au _futur flipping_

## Monitorer, Mesurer, Alerter

- le monitoring et l'alerting est tr√®s important pout suivre les fonctionnalit√©, s'assurer qu'elles marchent en prod et d√©cider si on peut les enlever.
- aucune feature ne marche tant qu'elle n'est pas suivie mesurable
- quand on a des mesures solides, on peut mettre en place de l'alerting
- les mesures peuvent nous permettre de prendre de d√©cisions
- les alertes doivent √™tre actionnable pour ne pas faire du bruit inutile
- de l'importance de la data dans les d√©cisions

## Limiter, surveiller et mettre √† jour ses d√©pendances

- sans m√™me toucher √† votre projet, il p√©rime de lui-m√™me avec ses d√©pendances
- il faut mieux parfois √©viter de dependre de lib non maintenues
- les libs de composants graphique peuvent vous aider au d√©but, mais elle cr√©eent des interd√©pendances
- yarn audit task
- yarn outdated et dependabot

## Partager, pr√©senter, documenter

- Review, et chorum important
- Mob Review
- D√©mo
- LFT
- Documentation et ADR

## Accepter sa dette technique

Un projet accumulera toujours de la dette technique.
C'est un fait.
Que ce soit de la dette volontaire ou involontaire, un projet qui r√©siste aux ann√©es va forc√©ment accumuler de la dette.
D'autant plus, si pendant toutes ces ann√©es vous continuez d'ajouter des fonctionnalit√©s.

Depuis 2014, nos bonnes pratiques, nos fa√ßons de faire ont bien √©volu√©.
Parfois nous avons d√©cid√© ces changements mais parfois nous les avons subi (un exemple, l'arriv√©e des composants fonctionnels avec React et l'api des Hooks).

**Notre projet n'est pas _"state of art"_ et on l'assume.**

![√ßa tiendra !](./leak.gif)

Nous essayons de prioriser nos sujets de _refactoring_ sur les parties de l'application sur lequel on a le plus de souci, le plus de peine.
On consid√®re qu'une partie de l'application qui nous pla√Æt pas mais sur laquelle on n'a pas besoin de travailler (apporter des √©volution) ne m√©rite pas qu'on la refactor.

Je pourrais vous citer de nombreuses fonctionnalit√©s de notre application qui n'ont pas √©volu√© fonctionnellement depuis plusieurs ann√©es.
Mais comme nous avons couvert ces fonctionnalit√©s de tests E2E depuis le d√©but, nous n'avons pas vraiment eu √† y retoucher.

Comme dit plus haut, la prochaine √©volution d'un bon de code est parfois sa d√©sactivation.
Alors pourquoi passez son temps √† r√©-√©crire toute l'application ?

- Le code devient dans tous les cas du "legacy".
- Tant que les fonctionnalit√©s sont test√©es, rien ne nous oblige √† tout refactorer en permanence pour que toute notre codebase soit _state of art_.
- On se focus sur nos pain point, on refactor ce qu'on a vraiment besoin de faire √©voluer.

## Pour r√©sumer

Les bonnes pratiques pr√©sent√©es ici restent bien √©videmment subjectives et ne s'appliqueront pas parfaitement/directement dans vos contextes.
Je suis cependant convaincu qu'elles peuvent probablement vous aider √† identifier ce qui peut faire passer votre projet de fun √† p√©rim√©.
√Ä Bedrock nous avons mis en place d'autres pratiques que je n'ai pas list√©es ici mais ce sera l'occasion de faire un nouvel article un jour.

Enfin, si vous souhaitez que je revienne plus en d√©tail sur certains chapitres pr√©sent√©s ici, n'h√©sitez pas √† me le dire, je pourrais essayer d'y d√©dier un article sp√©cifique.

[jest]: https://jestjs.io/fr/
[enzymejs]: https://enzymejs.github.io/enzyme/
[react testing library]: https://testing-library.com/docs/react-testing-library/intro/
[kpi]: https://www.journaldunet.fr/business/dictionnaire-du-marketing/1198189-kpi-key-performance-indicator-marketing-definition-exemples-okr/
